{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4  NumPy Basics: Arrays and Vectorized Computation\n",
    "\n",
    "NumPy, an abbreviation for Numerical Python, stands as a fundamental package in Python for numerical computing. It serves as a crucial component for various computational packages that offer scientific functionalities, using NumPy's array objects as a standard interface for seamless data exchange. The insights shared about NumPy are also applicable to pandas.\n",
    "\n",
    "Key features of NumPy include:\n",
    "\n",
    "1. **ndarray**: An efficient multidimensional array that facilitates rapid array-oriented arithmetic operations and offers versatile broadcasting capabilities.\n",
    "\n",
    "2. **Mathematical Functions**: Quick operations on entire arrays of data without the need for explicit loops.\n",
    "\n",
    "3. **Data I/O Tools**: Facilities for reading/writing array data to disk and working with memory-mapped files.\n",
    "\n",
    "4. **Linear Algebra, Random Number Generation, and Fourier Transform Capabilities**: Providing a comprehensive set of tools for these essential mathematical operations.\n",
    "\n",
    "5. **C API**: NumPy offers a C API, enabling seamless connectivity with libraries written in C, C++, or FORTRAN. This interoperability enhances the integration of NumPy with other programming languages.\n",
    "\n",
    "NumPy's robust and well-documented C API facilitates the seamless transfer of data between Python and external libraries coded in lower-level languages. This capability streamlines the integration of NumPy arrays with external libraries, making Python an optimal choice for wrapping legacy codebases in C, C++, or FORTRAN. The result is a dynamic and easily accessible interface.\n",
    "\n",
    "Although NumPy itself doesn't offer modeling or specific scientific functionalities, a solid grasp of NumPy arrays and array-oriented computing is invaluable for efficiently utilizing tools with array computing semantics, such as pandas. While this introduction provides a foundational understanding, the breadth of NumPy's capabilities is vast. Advanced features like broadcasting will be explored more comprehensively in subsequent sections (refer to Appendix A: Advanced NumPy). While these advanced features may not be necessary for the current context, they prove beneficial as you delve deeper into the realm of scientific computing in Python.\n",
    "\n",
    "In the context of data analysis applications, my primary emphasis will be on the following key functionalities:\n",
    "\n",
    "1. **Fast Array-Based Operations**: Utilizing efficient operations for data manipulation and cleaning, including tasks such as subsetting, filtering, transformation, and various computational operations.\n",
    "\n",
    "2. **Common Array Algorithms**: Employing standard array algorithms like sorting, unique operations, and set operations to handle data effectively.\n",
    "\n",
    "3. **Efficient Descriptive Statistics**: Calculating descriptive statistics with efficiency and aggregating/summarizing data in a manner that optimizes computational resources.\n",
    "\n",
    "4. **Data Alignment and Relational Manipulations**: Performing operations related to data alignment and manipulating relational aspects for merging and joining heterogeneous datasets seamlessly.\n",
    "\n",
    "5. **Expressing Conditional Logic as Array Expressions**: Utilizing array expressions to articulate conditional logic, avoiding the need for traditional loops with if-elif-else branches and thereby enhancing code efficiency.\n",
    "\n",
    "6. **Group-wise Data Manipulations**: Conducting manipulations on data in a group-wise fashion, encompassing aggregation, transformation, and the application of functions tailored to specific groups within the dataset.\n",
    "\n",
    "NumPy serves as a fundamental framework for general numerical data processing, offering a solid computational foundation. However, for readers engaging in statistical analysis or analytics, particularly on tabular data, pandas is often the preferred choice. Pandas extends beyond the capabilities of NumPy by providing additional domain-specific functionalities, such as specialized tools for time series manipulation, which are not inherently available in NumPy. Therefore, while NumPy lays the groundwork for numerical computations, pandas becomes the go-to tool for a broader spectrum of data analytics tasks, especially those involving structured and tabular data.\\\n",
    "\n",
    "Important to note is the origin of array-oriented computing in Python, dating back to 1995 when Jim Hugunin developed the Numeric library. In the subsequent decade, various scientific programming communities adopted array programming in Python. However, by the early 2000s, the library ecosystem had become fragmented. In 2005, Travis Oliphant played a pivotal role in unifying the community by consolidating the Numeric and Numarray projects into the NumPy project. This initiative successfully brought together diverse communities under a single and cohesive array computing framework.\n",
    "\n",
    "The significance of NumPy in numerical computations within Python arises from its design, specifically tailored for efficiency when handling large arrays of data. Several factors contribute to this efficiency:\n",
    "\n",
    "1. **Contiguous Memory Storage**: NumPy internally organizes data in a continuous block of memory, independent of other native Python objects. This allows NumPy's C-based algorithms to operate on this memory seamlessly, free from the constraints of type checking or additional overhead. In contrast, native Python sequences lack this contiguous memory structure.\n",
    "\n",
    "2. **C-Language Algorithms**: NumPy's extensive library of algorithms is implemented in the C language. This design choice enables these algorithms to efficiently process data, contributing to enhanced performance. The absence of type checking or other overhead in C-based operations further accelerates computation.\n",
    "\n",
    "3. **Reduced Memory Usage**: NumPy arrays are optimized to consume significantly less memory compared to built-in Python sequences. This efficiency in memory utilization is crucial when handling large datasets.\n",
    "\n",
    "4. **Vectorized Operations**: NumPy allows for complex computations to be performed on entire arrays without the need for explicit Python for loops. This vectorized approach eliminates the inefficiencies associated with looping through large sequences in regular Python code. As a result, NumPy operations outpace their counterparts in regular Python code, especially when dealing with substantial datasets.\n",
    "\n",
    "The performance difference between NumPy and pure Python becomes evident when considering a NumPy array of one million integers and its equivalent Python list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_arr = np.arange(1_000_000)\n",
    "my_list = list(range(1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform a simple operation of multiplying each element by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 µs ± 51.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_arr2 = my_arr * 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.4 ms ± 7.45 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit my_list2 = [x * 2 for x in my_list] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results highlight a substantial performance gap. NumPy's array-based operation takes only 309 microseconds per loop, while the equivalent Python list operation requires 46.4 milliseconds per loop. In general, NumPy-based algorithms demonstrate a speed improvement of 10 to 100 times (or more) compared to their pure Python counterparts, along with the added benefit of reduced memory usage. This stark contrast underscores the efficiency gains achieved by leveraging NumPy for numerical computations in Python.\n",
    "\n",
    "## 4.1 The NumPy ndarray: A Multidimensional Array Object\n",
    "\n",
    "A crucial component of NumPy is its N-dimensional array object, referred to as ndarray. This data structure serves as a rapid and adaptable container for managing substantial datasets in Python. Arrays empower users to execute mathematical operations on entire blocks of data, employing syntax that mirrors the conventions used for equivalent operations between individual scalar elements. This capability not only enhances computational efficiency but also facilitates the manipulation and analysis of large datasets with a concise and intuitive syntax. The ndarray's versatility makes it a cornerstone for numerical computing in Python, providing a powerful tool for handling complex mathematical operations on multidimensional data.\n",
    "\n",
    "To illustrate how NumPy facilitates batch computations with a syntax similar to scalar values on built-in Python objects, let's consider a simple example. After importing NumPy, a small array is created:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5, -0.1,  3. ],\n",
       "       [ 0. , -3. ,  6.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([[1.5, -0.1, 3], [0, -3, 6.5]])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, mathematical operations can be performed with the array 'data':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15.,  -1.,  30.],\n",
       "       [  0., -30.,  65.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. , -0.2,  6. ],\n",
       "       [ 0. , -6. , 13. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data + data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example, all elements of the array have been multiplied by 10. In the second example, corresponding values in each \"cell\" of the array have been added to each other. This demonstrates how NumPy allows for efficient and concise batch operations on entire arrays, mimicking the syntax used for individual scalar values in regular Python operations.\n",
    "\n",
    "It's noteworthy that in this chapter and throughout the book, we adhere to the standard NumPy convention of importing it as `import numpy as np`. While it's technically feasible to use `from numpy import *` in your code to avoid the need for `np.` prefixes, I strongly discourage adopting this practice. The NumPy namespace is extensive and includes functions with names that might clash with built-in Python functions (e.g., `min` and `max`). Adhering to standard conventions, such as importing NumPy with an alias (`np`), is generally recommended to prevent potential naming conflicts and maintain code clarity.\n",
    "\n",
    "An ndarray in NumPy serves as a versatile multidimensional container designed for homogeneous data, meaning that all its elements must be of the same type. Each array possesses two essential attributes:\n",
    "\n",
    "1. **Shape**: This is represented as a tuple, indicating the size of each dimension within the array. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this example, the array 'data' has a shape of (2, 3), signifying two rows and three columns.\n",
    "\n",
    " 2. **Data Type (dtype)**: This attribute is an object that describes the type of data stored in the array. It can be queried as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the elements of the 'data' array are of type float64. The dtype provides information about the nature of the data within the array.\n",
    "\n",
    "This chapter aims to provide a foundational understanding of using NumPy arrays, offering sufficient knowledge to follow the subsequent chapters of the book. While a deep comprehension of NumPy might not be imperative for many data analytical applications, acquiring proficiency in array-oriented programming and adopting a mindset oriented towards arrays is crucial for advancing towards expertise in scientific Python.\n",
    "\n",
    "**Note:** Throughout the book, when the terms \"array,\" \"NumPy array,\" or \"ndarray\" are used in the text, they typically allude to the ndarray object within the NumPy library.\n",
    "\n",
    "### Creating ndarrays\n",
    "\n",
    "Creating an array is straightforward using the array function in NumPy. This function accepts any sequence-like object, including other arrays, and generates a new NumPy array containing the provided data. A common choice for conversion is a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6. , 7.5, 8. , 0. , 1. ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = [6, 7.5, 8, 0, 1]\n",
    "arr1 = np.array(data1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a Python list called `data1` is converted into a NumPy array named `arr1` using the `np.array` function. The resulting array `arr1` contains the data from the original list.\n",
    "\n",
    "Nested sequences, such as a list of equal-length lists, will be converted into a multidimensional array using NumPy's array function. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
    "arr2 = np.array(data2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since `data2` is a list of lists, the resulting NumPy array `arr2` has two dimensions, with the shape automatically inferred from the data. We can verify this by checking the `ndim` (number of dimensions) and `shape` attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ndim` attribute indicates that the array has two dimensions, and the `shape` attribute specifies the size of each dimension (2 rows and 4 columns in this example).\n",
    "\n",
    "By default, unless explicitly specified (as discussed later in the chapter on Data Types for ndarrays), the `numpy.array` function attempts to infer a suitable data type for the array it creates. The determined data type is stored in a special dtype metadata object. In the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example (`arr1`), where the input data included floating-point numbers, NumPy inferred the data type as 'float64'. In the second example (`arr2`), where the input data consisted of integers, NumPy inferred the data type as 'int64'. This automatic inference ensures that the created array is appropriately typed based on the provided data.\n",
    "\n",
    "In addition to `numpy.array`, several other functions in NumPy facilitate the creation of new arrays. For instance, `numpy.zeros` and `numpy.ones` generate arrays filled with 0s or 1s, respectively, based on a specified length or shape. The `numpy.empty` function creates an array without initializing its values to any particular value. For higher-dimensional arrays, you can pass a tuple indicating the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.66900113e-310, 0.00000000e+000],\n",
       "        [1.01855798e-312, 9.54898106e-313],\n",
       "        [1.20953760e-312, 1.03977794e-312]],\n",
       "\n",
       "       [[1.23075756e-312, 1.10343781e-312],\n",
       "        [1.06099790e-312, 9.76118064e-313],\n",
       "        [1.10343781e-312, 1.90979621e-312]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((2, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution:** It's essential to note that `numpy.empty` does not guarantee an array filled with zeros. This function returns uninitialized memory, potentially containing non-zero \"garbage\" values. Therefore, it should only be used if the intention is to populate the new array with specific data.\n",
    "\n",
    "`numpy.arange` serves as an array-valued counterpart to the built-in Python `range` function. It generates an array containing a sequence of numbers within the specified range. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `np.arange(15)` produces a NumPy array with values ranging from 0 to 14, similar to the output of the `range` function in Python. The primary distinction is that `numpy.arange` creates an array directly, offering a more convenient and array-oriented approach compared to the standard Python `range` function.\n",
    "\n",
    "The table below provides a concise overview of some important NumPy array creation functions:\n",
    "\n",
    "Table 4.1: Some important NumPy array creation functions\n",
    "\n",
    "| Function   | Description                                                                                                                                                                   |\n",
    "|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `array`    | Converts input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a data type or explicitly specifying a data type; copies the input data by default                                                |\n",
    "| `asarray`  | Converts input to an ndarray, but does not copy if the input is already an ndarray                                                                                           |\n",
    "| `arange`   | Similar to the built-in `range` but returns an ndarray instead of a list                                                                                                      |\n",
    "| `ones`, `ones_like` | Produces an array of all 1s with the given shape and data type; `ones_like` takes another array and produces a ones array of the same shape and data type                 |\n",
    "| `zeros`, `zeros_like` | Similar to `ones` and `ones_like` but produces arrays of 0s instead                                                                                                              |\n",
    "| `empty`, `empty_like` | Creates new arrays by allocating new memory, but does not populate with any values like `ones` and `zeros`                                                                   |\n",
    "| `full`, `full_like`   | Produces an array of the given shape and data type with all values set to the indicated \"fill value\"; `full_like` takes another array and produces a filled array of the same shape and data type |\n",
    "| `eye`, `identity`     | Creates a 2D identity matrix with ones on the diagonal and zeros elsewhere (`identity` is equivalent to `eye`)                                                               |\n",
    "\n",
    "These functions are valuable tools for efficiently creating arrays with specific shapes, data types, and fill values, catering to various needs in numerical computing with NumPy.\n",
    "\n",
    "\n",
    "### Data Types for ndarrays\n",
    "\n",
    "The data type, represented by the `dtype` attribute, is a special object in NumPy that contains the metadata necessary for an ndarray to interpret a chunk of memory as a specific type of data. Here's an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array([1, 2, 3], dtype=np.float64)\n",
    "arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = np.array([1, 2, 3], dtype=np.int32)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `arr1` is explicitly assigned a data type of `float64`, indicating that each element in the array should be interpreted as a 64-bit floating-point number. Similarly, `arr2` is assigned a data type of `int32`, specifying that each element should be treated as a 32-bit integer. The `dtype` attribute provides insights into the nature of the data stored in the array.\n",
    "\n",
    "Data types in NumPy contribute to its flexibility when dealing with data from various sources. These data types often directly map onto the underlying memory or disk representation, facilitating the reading and writing of binary data streams to disk. This feature also enables seamless integration with code written in low-level languages like C or FORTRAN.\n",
    "\n",
    "Numerical data types in NumPy are named by combining a type name (e.g., float or int) with a number indicating the number of bits per element. For instance, a standard double-precision floating-point value, equivalent to Python's float object, occupies 8 bytes or 64 bits. In NumPy, this type is denoted as `float64`. The naming convention allows for clear and precise specification of the data type.\n",
    "\n",
    "For a comprehensive listing of NumPy's supported data types, refer to Table 4.2. This information is crucial for understanding and managing the memory representation of data in NumPy arrays.\n",
    "\n",
    "Here is a concise table summarizing NumPy's data types:\n",
    "\n",
    "**Table 4.2: NumPy Data Types**\n",
    "\n",
    "| Type                     | Type Code | Description                                                                                         |\n",
    "|--------------------------|-----------|-----------------------------------------------------------------------------------------------------|\n",
    "| `int8`, `uint8`          | `i1`, `u1`| Signed and unsigned 8-bit (1 byte) integer types                                                    |\n",
    "| `int16`, `uint16`        | `i2`, `u2`| Signed and unsigned 16-bit integer types                                                           |\n",
    "| `int32`, `uint32`        | `i4`, `u4`| Signed and unsigned 32-bit integer types                                                           |\n",
    "| `int64`, `uint64`        | `i8`, `u8`| Signed and unsigned 64-bit integer types                                                           |\n",
    "| `float16`                | `f2`      | Half-precision floating point                                                                      |\n",
    "| `float32`                | `f4` or `f`| Standard single-precision floating point; compatible with C float                                  |\n",
    "| `float64`                | `f8` or `d`| Standard double-precision floating point; compatible with C double and Python float object         |\n",
    "| `float128`               | `f16` or `g`| Extended-precision floating point                                                                 |\n",
    "| `complex64`, `complex128`, `complex256` | `c8`, `c16`, `c32` | Complex numbers represented by two 32, 64, or 128 floats, respectively                   |\n",
    "| `bool`                   | `?`       | Boolean type storing True and False values                                                        |\n",
    "| `object`                 | `O`       | Python object type; a value can be any Python object                                               |\n",
    "| `string_`                | `S`       | Fixed-length ASCII string type (1 byte per character); for example, to create a string data type with length 10, use 'S10' |\n",
    "| `unicode_`               | `U`       | Fixed-length Unicode type (number of bytes platform-specific); same specification semantics as `string_` (e.g., 'U10') |\n",
    "\n",
    "It's important to note that there's no need to memorize all the NumPy data types, especially if you're a new user. In many cases, it suffices to be aware of the general kind of data you're working with, such as floating-point, complex, integer, Boolean, string, or general Python objects. \n",
    "\n",
    "As you become more experienced, you may find it beneficial to understand the specifics of data types, especially when dealing with memory and disk storage, particularly with large datasets. Having control over the storage type can be advantageous in optimizing performance and memory usage for your specific use cases. So, while it's not necessary to memorize every detail, having a general understanding of the available options can be valuable as you gain more experience with NumPy.\n",
    "\n",
    "You can explicitly convert or cast an array from one data type to another using the `astype` method of the ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "arr.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_arr = arr.astype(np.float64)\n",
    "float_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_arr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, integers were cast to floating point. If you cast floating-point numbers to an integer data type, the decimal part will be truncated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.7, -1.2, -2.6,  0.5, 12.9, 10.1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])\n",
    "arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, -1, -2,  0, 12, 10], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an array of strings representing numbers, you can use `astype` to convert them to numeric form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25, -9.6 , 42.  ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_strings = np.array([\"1.25\", \"-9.6\", \"42\"], dtype=np.string_)\n",
    "numeric_strings.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be cautious when using the `numpy.string_` type, as string data in NumPy is fixed-size and may truncate input without warning. If casting fails for some reason (e.g., a string that cannot be converted to `float64`), a `ValueError` will be raised.\n",
    "\n",
    "You can also use another array’s dtype attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_array = np.arange(10)\n",
    "calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)\n",
    "int_array.astype(calibers.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are shorthand type code strings you can use to refer to a dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_uint32 = np.zeros(8, dtype=\"u4\")\n",
    "zeros_uint32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that calling `astype` always creates a new array (a copy of the data), even if the new data type is the same as the old data type.\n",
    "\n",
    "### Arithmetic with NumPy Arrays\n",
    "\n",
    "Arrays in NumPy are crucial for expressing batch operations on data without the need for explicit for loops. This capability is often referred to as \"vectorization\" among NumPy users. Any arithmetic operations performed between equal-size arrays apply the operation element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr * arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr - arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic operations with scalars propagate the scalar argument to each element in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5       , 0.33333333],\n",
       "       [0.25      , 0.2       , 0.16666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons between arrays of the same size yield Boolean arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  4.,  1.],\n",
       "       [ 7.,  2., 12.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False],\n",
       "       [ True, False,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 > arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating operations between differently sized arrays is known as \"broadcasting\" and will be discussed in more detail in Appendix A: Advanced NumPy. However, a deep understanding of broadcasting is not necessary for most of this book.\n",
    "\n",
    "### Basic Indexing and Slicing\n",
    "\n",
    "NumPy array indexing is a nuanced topic with various ways to select subsets of data or individual elements. One-dimensional arrays behave similarly to Python lists on the surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[5:8] = 12\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a scalar value to a slice, as in `arr[5:8] = 12`, broadcasts the value to the entire selection.\n",
    "\n",
    "**Note:** An important distinction from Python's built-in lists is that array slices in NumPy are views on the original array. This implies that the data is not copied, and any modifications made to the view will be reflected in the source array. This is different from lists in Python, where slices create a new list with copied data.\n",
    "\n",
    "To illustrate this behavior, let's create a slice of the array `arr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_slice = arr[5:8]\n",
    "arr_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we modify values in `arr_slice`, the changes will be reflected in the original array `arr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2,     3,     4,    12, 12345,    12,     8,\n",
       "           9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_slice[1] = 12345\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the \"bare\" slice `[:]` will assign the specified value to all elements in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_slice[:] = 64\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're new to NumPy, this behavior might be surprising, especially if you're accustomed to other array programming languages that copy data more eagerly. NumPy's design allows it to work efficiently with large arrays, and copying data for every operation could lead to performance and memory issues.\n",
    "\n",
    "**Caution:** If you want a copy of a slice of an ndarray instead of a view, you need to explicitly copy the array, for example, `arr[5:8].copy()`. This behavior is also observed in pandas.\n",
    "\n",
    "With higher-dimensional arrays, you have more options. In a two-dimensional array, the elements at each index are no longer scalars but rather one-dimensional arrays:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "arr2d[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual elements can be accessed recursively. However, to simplify this process, you can pass a comma-separated list of indices to select individual elements. The following examples are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[0][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notation allows for more concise and readable indexing when working with multi-dimensional arrays.\n",
    "\n",
    "In multidimensional arrays, if you omit later indices, the returned object will be a lower-dimensional ndarray consisting of all the data along the higher dimensions. For example, in the 2 × 2 × 3 array `arr3d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `arr3d[0]` is a 2 × 3 array. Both scalar values and arrays can be assigned to `arr3d[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[42, 42, 42],\n",
       "        [42, 42, 42]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_values = arr3d[0].copy()\n",
    "arr3d[0] = 42\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d[0] = old_values\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, `arr3d[1, 0]` gives you all the values whose indices start with `(1, 0)`, forming a one-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expression is equivalent to indexing in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = arr3d[1]\n",
    "x\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in all these cases where subsections of the array have been selected, the returned arrays are views.\n",
    "\n",
    "**Caution:** This multidimensional indexing syntax for NumPy arrays will not work with regular Python objects, such as lists of lists.\n",
    "\n",
    "### Indexing with slices\n",
    "\n",
    "Similar to one-dimensional objects like Python lists, ndarrays support slicing using the familiar syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when dealing with a two-dimensional array like `arr2d`, slicing works differently. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the slice `arr2d[:2]` selects the first two rows along axis 0. It's useful to interpret it as \"select the first two rows of `arr2d`.\"\n",
    "\n",
    "You can use multiple slices, similar to multiple indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[:2, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When slicing, the resulting arrays are always views with the same number of dimensions. By combining integer indexes and slices, you can obtain lower-dimensional slices. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_dim_slice = arr2d[1, :2]\n",
    "lower_dim_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `arr2d` is two-dimensional, `lower_dim_slice` is one-dimensional. Refer to Figure 4.2 for a visual representation. It's important to understand that a standalone colon implies selecting the entire axis. Consequently, you can perform slicing exclusively on higher-dimensional axes using this notation.\n",
    "\n",
    "![Figure 4.2: Two-dimensional array slicing](images/pda3_0402.png)\n",
    "\n",
    "You can also select specific columns or rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_dim_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[:2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4],\n",
       "       [7]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[:, :1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning values to a slice modifies the original array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [4, 0, 0],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[:2, 1:] = 0\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing\n",
    "\n",
    "Let's examine a scenario where we have two NumPy arrays: one containing names with duplicates and the other containing corresponding data in rows. The task is to select rows from the data array based on a specific name, such as \"Bob.\"\n",
    "\n",
    "```python\n",
    "# Original Code\n",
    "import numpy as np\n",
    "\n",
    "# Arrays with names and corresponding data\n",
    "names = np.array([\"Bob\", \"Joe\", \"Will\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n",
    "data = np.array([[4, 7], [0, 2], [-5, 6], [0, 0], [1, 2], [-12, -4], [3, 4]])\n",
    "\n",
    "# Selecting rows where names == \"Bob\"\n",
    "selected_rows = data[names == \"Bob\"]\n",
    "print(selected_rows)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Suppose each name corresponds to a row in the data array. To select rows with the name \"Bob,\" we use Boolean indexing. The comparison `names == \"Bob\"` creates a Boolean array, indicating True where the condition is met and False otherwise.\n",
    "\n",
    "```python\n",
    "# Boolean array indicating where names == \"Bob\"\n",
    "name_condition = names == \"Bob\"\n",
    "print(name_condition)\n",
    "```\n",
    "\n",
    "The Boolean array can be used to index the data array, selecting rows where the condition is True.\n",
    "\n",
    "```python\n",
    "# Selecting rows where names == \"Bob\"\n",
    "selected_rows = data[name_condition]\n",
    "print(selected_rows)\n",
    "```\n",
    "\n",
    "You can also perform more complex selections, such as selecting specific columns along with the rows.\n",
    "\n",
    "```python\n",
    "# Selecting columns from rows where names == \"Bob\"\n",
    "selected_columns = data[names == \"Bob\", 1:]\n",
    "print(selected_columns)\n",
    "```\n",
    "\n",
    "To select everything but \"Bob,\" you can use the `!=` operator or negate the condition using `~`.\n",
    "\n",
    "```python\n",
    "# Selecting rows where names != \"Bob\"\n",
    "rows_except_bob = data[names != \"Bob\"]\n",
    "print(rows_except_bob)\n",
    "```\n",
    "\n",
    "The `~` operator can be useful for inverting a Boolean array referenced by a variable.\n",
    "\n",
    "```python\n",
    "# Inverting the condition using ~\n",
    "condition = names == \"Bob\"\n",
    "inverted_condition = ~condition\n",
    "print(data[inverted_condition])\n",
    "```\n",
    "\n",
    "You can combine multiple conditions using Boolean arithmetic operators like `&` (and) and `|` (or).\n",
    "\n",
    "```python\n",
    "# Combining conditions using | (or)\n",
    "combined_condition = (names == \"Bob\") | (names == \"Will\")\n",
    "print(data[combined_condition])\n",
    "```\n",
    "\n",
    "It's essential to note that setting values with Boolean arrays involves substituting values on the right-hand side into locations where the Boolean array's values are True.\n",
    "\n",
    "```python\n",
    "# Setting negative values in data to 0\n",
    "data[data < 0] = 0\n",
    "print(data)\n",
    "```\n",
    "\n",
    "Setting values with Boolean arrays creates a copy of the data, even if the returned array is unchanged.\n",
    "\n",
    "Finally, it's crucial to use `&` and `|` instead of the `and` and `or` keywords when working with Boolean arrays. Also, setting whole rows or columns using a one-dimensional Boolean array is possible.\n",
    "\n",
    "```python\n",
    "# Setting whole rows based on a condition\n",
    "data[names != \"Joe\"] = 7\n",
    "print(data)\n",
    "```\n",
    "\n",
    "These operations on two-dimensional data can be efficiently performed using pandas, as we will explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,   7],\n",
       "       [  0,   2],\n",
       "       [ -5,   6],\n",
       "       [  0,   0],\n",
       "       [  1,   2],\n",
       "       [-12,  -4],\n",
       "       [  3,   4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = np.array([\"Bob\", \"Joe\", \"Will\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n",
    "data = np.array([[4, 7], [0, 2], [-5, 6], [0, 0], [1, 2],\n",
    "                 [-12, -4], [3, 4]])\n",
    "names\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names == \"Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 7],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[names == \"Bob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[names == \"Bob\", 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[names == \"Bob\", 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names != \"Bob\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~(names == \"Bob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2],\n",
       "       [ -5,   6],\n",
       "       [  1,   2],\n",
       "       [-12,  -4],\n",
       "       [  3,   4]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~(names == \"Bob\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2],\n",
       "       [ -5,   6],\n",
       "       [  1,   2],\n",
       "       [-12,  -4],\n",
       "       [  3,   4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = names == \"Bob\"\n",
    "data[~cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7],\n",
       "       [-5,  6],\n",
       "       [ 0,  0],\n",
       "       [ 1,  2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (names == \"Bob\") | (names == \"Will\")\n",
    "mask\n",
    "data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 7],\n",
       "       [0, 2],\n",
       "       [0, 6],\n",
       "       [0, 0],\n",
       "       [1, 2],\n",
       "       [0, 0],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data < 0] = 0\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7],\n",
       "       [0, 2],\n",
       "       [7, 7],\n",
       "       [7, 7],\n",
       "       [7, 7],\n",
       "       [0, 0],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[names != \"Joe\"] = 7\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing\n",
    "\n",
    "Fancy indexing is a term used in NumPy to describe the process of indexing arrays using integer arrays. Suppose we have an 8 × 4 array:\n",
    "\n",
    "```python\n",
    "# Original Code\n",
    "import numpy as np\n",
    "\n",
    "arr = np.zeros((8, 4))\n",
    "\n",
    "for i in range(8):\n",
    "    arr[i] = i\n",
    "\n",
    "# Displaying the array\n",
    "print(arr)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "In the above code, we create an array `arr` with eight rows and four columns. Each row is filled with the corresponding index value.\n",
    "\n",
    "To select a subset of rows in a specific order, you can use a list or ndarray of integers to specify the desired order:\n",
    "\n",
    "```python\n",
    "# Selecting rows in a specific order\n",
    "selected_rows = arr[[4, 3, 0, 6]]\n",
    "print(selected_rows)\n",
    "```\n",
    "\n",
    "You can also use negative indices to select rows from the end:\n",
    "\n",
    "```python\n",
    "# Selecting rows using negative indices\n",
    "selected_rows_negative = arr[[-3, -5, -7]]\n",
    "print(selected_rows_negative)\n",
    "```\n",
    "\n",
    "If you pass multiple index arrays, it selects a one-dimensional array of elements corresponding to each tuple of indices:\n",
    "\n",
    "```python\n",
    "# Selecting elements using multiple index arrays\n",
    "arr = np.arange(32).reshape((8, 4))\n",
    "selected_elements = arr[[1, 5, 7, 2], [0, 3, 1, 2]]\n",
    "print(selected_elements)\n",
    "```\n",
    "\n",
    "It's important to note that the result of fancy indexing with as many integer arrays as there are axes is always one-dimensional.\n",
    "\n",
    "The behavior of fancy indexing might differ from expectations when users aim to select a rectangular region formed by choosing a subset of both rows and columns. To achieve this, you can use two separate sets of indices:\n",
    "\n",
    "```python\n",
    "# Selecting a rectangular region using fancy indexing\n",
    "rectangular_region = arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]\n",
    "print(rectangular_region)\n",
    "```\n",
    "\n",
    "It's crucial to understand that fancy indexing, unlike slicing, always creates a new array when assigning the result to a new variable. If values are assigned with fancy indexing, the indexed values in the original array will be modified:\n",
    "\n",
    "```python\n",
    "# Modifying values using fancy indexing\n",
    "modified_values = arr[[1, 5, 7, 2], [0, 3, 1, 2]]\n",
    "print(modified_values)\n",
    "\n",
    "# Assigning new values to the indexed positions\n",
    "arr[[1, 5, 7, 2], [0, 3, 1, 2]] = 0\n",
    "print(arr)\n",
    "```\n",
    "\n",
    "These operations demonstrate the behavior of fancy indexing, providing flexibility in selecting specific elements or subsets of an array based on integer indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5.],\n",
       "       [6., 6., 6., 6.],\n",
       "       [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros((8, 4))\n",
    "for i in range(8):\n",
    "    arr[i] = i\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4., 4.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [6., 6., 6., 6.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[4, 3, 0, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., 5.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[-3, -5, -7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23],\n",
       "       [24, 25, 26, 27],\n",
       "       [28, 29, 30, 31]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(32).reshape((8, 4))\n",
    "arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 23, 29, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2], [0, 3, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7,  5,  6],\n",
       "       [20, 23, 21, 22],\n",
       "       [28, 31, 29, 30],\n",
       "       [ 8, 11,  9, 10]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 0,  5,  6,  7],\n",
       "       [ 8,  9,  0, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22,  0],\n",
       "       [24, 25, 26, 27],\n",
       "       [28,  0, 30, 31]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2], [0, 3, 1, 2]]\n",
    "arr[[1, 5, 7, 2], [0, 3, 1, 2]] = 0\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing Arrays and Swapping Axes\n",
    "\n",
    "Transposing is a specific form of reshaping that allows you to obtain a view of the underlying data without copying it. Arrays in NumPy provide the `transpose` method and the special `T` attribute for this purpose:\n",
    "\n",
    "```python\n",
    "# Original Code\n",
    "import numpy as np\n",
    "\n",
    "arr = np.arange(15).reshape((3, 5))\n",
    "\n",
    "# Displaying the array and its transpose\n",
    "print(arr)\n",
    "print(arr.T)\n",
    "```\n",
    "\n",
    "In the provided code, we create an array `arr` with dimensions 3x5. Transposing this array is achieved using the `T` attribute or the `transpose` method:\n",
    "\n",
    "```python\n",
    "# Transposing the array using .T\n",
    "transposed_arr = arr.T\n",
    "print(transposed_arr)\n",
    "```\n",
    "\n",
    "Transposing is particularly useful in matrix computations, such as when calculating the inner product using `numpy.dot`:\n",
    "\n",
    "```python\n",
    "# Performing matrix multiplication with the transposed array\n",
    "result = np.dot(arr.T, arr)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Alternatively, the `@` infix operator can be used for matrix multiplication:\n",
    "\n",
    "```python\n",
    "# Matrix multiplication using @ infix operator\n",
    "result_alternative = arr.T @ arr\n",
    "print(result_alternative)\n",
    "```\n",
    "\n",
    "Simple transposing with `.T` is essentially a special case of swapping axes. The `ndarray` class provides the `swapaxes` method, allowing you to switch specified axes and rearrange the data:\n",
    "\n",
    "```python\n",
    "# Swapping axes using swapaxes method\n",
    "swapped_arr = arr.swapaxes(0, 1)\n",
    "print(swapped_arr)\n",
    "```\n",
    "\n",
    "It is crucial to note that both transposing and swapping axes return views on the data without creating a new copy, maintaining efficiency in operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(15).reshape((3, 5))\n",
    "arr\n",
    "arr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 0], [1, 2, -2], [6, 3, 2], [-1, 0, -1], [1, 0, 1]])\n",
    "arr\n",
    "np.dot(arr.T, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.T @ arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr\n",
    "arr.swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudorandom Number Generation\n",
    "\n",
    "The `numpy.random` module enhances the capabilities of the built-in Python `random` module by providing functions to efficiently generate entire arrays of sample values from various probability distributions. For instance, you can obtain a 4 × 4 array of samples from the standard normal distribution using `numpy.random.standard_normal`:\n",
    "\n",
    "```python\n",
    "# Generating a 4x4 array of samples from the standard normal distribution\n",
    "samples = np.random.standard_normal(size=(4, 4))\n",
    "print(samples)\n",
    "```\n",
    "\n",
    "In contrast, Python's built-in `random` module generates only one value at a time. The performance difference becomes evident when benchmarking for very large samples:\n",
    "\n",
    "```python\n",
    "# Benchmarking with Python's random module\n",
    "from random import normalvariate\n",
    "N = 1_000_000\n",
    "\n",
    "%timeit samples = [normalvariate(0, 1) for _ in range(N)]\n",
    "\n",
    "# Benchmarking with numpy.random\n",
    "%timeit np.random.standard_normal(N)\n",
    "```\n",
    "\n",
    "The results show that `numpy.random` is significantly faster for generating large samples.\n",
    "\n",
    "While the generated numbers are pseudorandom, they are deterministically produced by a configurable random number generator. Functions like `numpy.random.standard_normal` utilize the default random number generator. However, you can configure your code to use an explicit generator:\n",
    "\n",
    "```python\n",
    "# Creating a random number generator object with a specified seed\n",
    "rng = np.random.default_rng(seed=12345)\n",
    "\n",
    "# Generating random data using the rng object\n",
    "data = rng.standard_normal((2, 3))\n",
    "```\n",
    "\n",
    "The `seed` argument determines the initial state of the generator, and the state changes with each use of the `rng` object. This generator object is isolated from other code that may use the `numpy.random` module.\n",
    "\n",
    "The `numpy.random` generator objects, such as `rng`, provide various methods for generating random numbers. Here is a partial list of these methods:\n",
    "\n",
    "|Method | Description\n",
    "|--- | ---\n",
    "|`permutation`| Return a random permutation of a sequence or permuted range.\n",
    "|`shuffle`| Randomly permute a sequence in place.\n",
    "|`uniform`| Draw samples from a uniform distribution.\n",
    "| `integers`| Draw random integers from a given low-to-high range.\n",
    "| `standard_normal`| Draw samples from a normal distribution with mean 0 and standard deviation 1.\n",
    "| `binomial`, `normal`, `beta`, `chisquare`, `gamma`| Draw samples from specific distributions.\n",
    "\n",
    "These methods offer flexibility for generating random data based on different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.standard_normal(size=(4, 4))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import normalvariate\n",
    "N = 1_000_000\n",
    "%timeit samples = [normalvariate(0, 1) for _ in range(N)]\n",
    "%timeit np.random.standard_normal(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12345)\n",
    "data = rng.standard_normal((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Universal Functions: Fast Element-Wise Array Functions\n",
    "\n",
    "A universal function, or ufunc, is a function designed for performing element-wise operations on data within ndarrays. Ufuncs act as fast, vectorized wrappers for basic functions that take one or more scalar values and produce one or more scalar results.\n",
    "\n",
    "Many ufuncs involve simple element-wise transformations, such as `numpy.sqrt` or `numpy.exp`. For instance:\n",
    "\n",
    "```python\n",
    "arr = np.arange(10)\n",
    "sqrt_result = np.sqrt(arr)\n",
    "exp_result = np.exp(arr)\n",
    "```\n",
    "\n",
    "Here, `sqrt` and `exp` are unary ufuncs, operating element-wise on the array `arr`.\n",
    "\n",
    "Other ufuncs, like `numpy.add` or `numpy.maximum`, are binary ufuncs. They take two arrays and produce a single array as a result:\n",
    "\n",
    "```python\n",
    "x = rng.standard_normal(8)\n",
    "y = rng.standard_normal(8)\n",
    "max_result = np.maximum(x, y)\n",
    "```\n",
    "\n",
    "In this example, `numpy.maximum` computes the element-wise maximum of the arrays `x` and `y`.\n",
    "\n",
    "Some ufuncs, such as `numpy.modf`, return multiple arrays. This function, a vectorized version of Python's built-in `math.modf`, separates the fractional and integral parts of a floating-point array:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal(7) * 5\n",
    "remainder, whole_part = np.modf(arr)\n",
    "```\n",
    "\n",
    "Ufuncs can also accept an optional `out` argument, allowing them to store their results in an existing array rather than creating a new one:\n",
    "\n",
    "```python\n",
    "arr = np.arange(10)\n",
    "out = np.zeros_like(arr)\n",
    "np.add(arr, 1, out=out)\n",
    "```\n",
    "\n",
    "The tables (Table 4.4 and Table 4.5) provide a listing of some of NumPy's unary and binary ufuncs along with their descriptions. NumPy continually adds new ufuncs, so referring to the online NumPy documentation is recommended for an updated and comprehensive list.\n",
    "\n",
    "\n",
    "**Table 4.4: Some unary universal functions**\n",
    "\n",
    "| Function            | Description                                                  |\n",
    "|---------------------|--------------------------------------------------------------|\n",
    "| abs, fabs           | Compute the absolute value element-wise for integer, floating-point, or complex values |\n",
    "| sqrt                | Compute the square root of each element (equivalent to arr ** 0.5) |\n",
    "| square              | Compute the square of each element (equivalent to arr ** 2)   |\n",
    "| exp                 | Compute the exponent ex of each element                       |\n",
    "| log, log10, log2, log1p | Natural logarithm (base e), log base 10, log base 2, and log(1 + x), respectively |\n",
    "| sign                | Compute the sign of each element: 1 (positive), 0 (zero), or –1 (negative) |\n",
    "| ceil                | Compute the ceiling of each element (i.e., the smallest integer greater than or equal to that number) |\n",
    "| floor               | Compute the floor of each element (i.e., the largest integer less than or equal to each element) |\n",
    "| rint                | Round elements to the nearest integer, preserving the dtype  |\n",
    "| modf                | Return fractional and integral parts of array as separate arrays |\n",
    "| isnan               | Return Boolean array indicating whether each value is NaN (Not a Number) |\n",
    "| isfinite, isinf    | Return Boolean array indicating whether each element is finite (non-inf, non-NaN) or infinite, respectively |\n",
    "| cos, cosh, sin, sinh, tan, tanh | Regular and hyperbolic trigonometric functions               |\n",
    "| arccos, arccosh, arcsin, arcsinh, arctan, arctanh | Inverse trigonometric functions                       |\n",
    "| logical_not         | Compute truth value of not x element-wise (equivalent to ~arr) |\n",
    "\n",
    "\n",
    "**Table 4.5: Some binary universal functions**\n",
    "\n",
    "| Function            | Description                                                  |\n",
    "|---------------------|--------------------------------------------------------------|\n",
    "| add                 | Add corresponding elements in arrays                          |\n",
    "| subtract            | Subtract elements in the second array from the first array    |\n",
    "| multiply            | Multiply array elements                                       |\n",
    "| divide, floor_divide | Divide or floor divide (truncating the remainder)              |\n",
    "| power               | Raise elements in the first array to powers indicated in the second array |\n",
    "| maximum, fmax       | Element-wise maximum; fmax ignores NaN                        |\n",
    "| minimum, fmin       | Element-wise minimum; fmin ignores NaN                        |\n",
    "| mod                 | Element-wise modulus (remainder of division)                  |\n",
    "| copysign            | Copy the sign of values in the second argument to values in the first argument |\n",
    "| greater, greater_equal, less, less_equal, equal, not_equal | Perform element-wise comparison, yielding a Boolean array (equivalent to infix operators >, >=, <, <=, ==, !=) |\n",
    "| logical_and         | Compute element-wise truth value of AND (&) logical operation  |\n",
    "| logical_or          | Compute element-wise truth value of OR (|) logical operation   |\n",
    "\n",
    "\n",
    "These tables provide a concise reference for some of the unary and binary universal functions available in NumPy along with their respective descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "arr\n",
    "np.sqrt(arr)\n",
    "np.exp(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rng.standard_normal(8)\n",
    "y = rng.standard_normal(8)\n",
    "x\n",
    "y\n",
    "np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(7) * 5\n",
    "arr\n",
    "remainder, whole_part = np.modf(arr)\n",
    "remainder\n",
    "whole_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr\n",
    "out = np.zeros_like(arr)\n",
    "np.add(arr, 1)\n",
    "np.add(arr, 1, out=out)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Array-Oriented Programming with Arrays\n",
    "\n",
    "Utilizing NumPy arrays allows you to succinctly represent various data processing tasks as array expressions, a practice commonly known as vectorization. This approach involves replacing explicit loops with array expressions, which generally results in significantly faster operations compared to their pure Python counterparts, especially in numerical computations. The efficiency gains are most notable in scenarios involving extensive numerical calculations. In the advanced section (Appendix A: Advanced NumPy), broadcasting, a potent technique for vectorizing computations, is elaborated.\n",
    "\n",
    "To illustrate, consider the task of evaluating the function sqrt(x^2 + y^2) across a regular grid of values. The numpy.meshgrid function efficiently generates two-dimensional matrices for all pairs of (x, y) from two one-dimensional arrays:\n",
    "\n",
    "```python\n",
    "points = np.arange(-5, 5, 0.01)  # 100 equally spaced points\n",
    "xs, ys = np.meshgrid(points, points)\n",
    "```\n",
    "\n",
    "Here, `xs` and `ys` represent the grid of x and y values, respectively. The function can then be evaluated using a straightforward expression:\n",
    "\n",
    "```python\n",
    "z = np.sqrt(xs ** 2 + ys ** 2)\n",
    "```\n",
    "\n",
    "The resulting array `z` holds the computed function values for each pair of (x, y). For visualization purposes, the matplotlib library is employed:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(z, cmap=plt.cm.gray, extent=[-5, 5, -5, 5])\n",
    "plt.colorbar()\n",
    "plt.title(\"Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values\")\n",
    "```\n",
    "\n",
    "In this example, `plt.imshow` creates an image plot based on the two-dimensional array `z`. The colormap (`cmap`), color scale (`extent`), and a color bar are configured for visual representation. This visualization offers insights into the behavior of the function across the specified grid of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.arange(-5, 5, 0.01) # 100 equally spaced points\n",
    "xs, ys = np.meshgrid(points, points)\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.sqrt(xs ** 2 + ys ** 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(z, cmap=plt.cm.gray, extent=[-5, 5, -5, 5])\n",
    "plt.colorbar()\n",
    "plt.title(\"Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressing Conditional Logic as Array Operations\n",
    "\n",
    "The `numpy.where` function is a vectorized alternative to the ternary expression `x if condition else y`. Consider having a Boolean array and two arrays of values:\n",
    "\n",
    "```python\n",
    "xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])\n",
    "yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])\n",
    "cond = np.array([True, False, True, True, False])\n",
    "```\n",
    "\n",
    "If the goal is to select a value from `xarr` whenever the corresponding value in `cond` is `True`, and otherwise take the value from `yarr`, a list comprehension might be used, as shown below:\n",
    "\n",
    "```python\n",
    "result = [(x if c else y) for x, y, c in zip(xarr, yarr, cond)]\n",
    "```\n",
    "\n",
    "However, this approach has drawbacks. It's not efficient for large arrays due to the interpreted Python code execution, and it doesn't support multidimensional arrays. The `numpy.where` function addresses these issues, allowing the same operation to be performed with a single function call:\n",
    "\n",
    "```python\n",
    "result = np.where(cond, xarr, yarr)\n",
    "```\n",
    "\n",
    "Here, the `numpy.where` function efficiently selects values from `xarr` where `cond` is `True` and from `yarr` where `cond` is `False`. The resulting array is `[1.1, 2.2, 1.3, 1.4, 2.5]`.\n",
    "\n",
    "Additionally, `numpy.where` can handle more complex scenarios. For instance, it can be used to replace positive values with 2 and negative values with -2 in a matrix of randomly generated data:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal((4, 4))\n",
    "result = np.where(arr > 0, 2, -2)\n",
    "```\n",
    "\n",
    "This produces an array where positive values are set to 2, negative values to -2, and the resulting array is `[[2, 2, 2, -2], [-2, -2, 2, 2], [-2, -2, 2, 2], [-2, 2, -2, -2]]`. Furthermore, the `numpy.where` function allows combining scalars and arrays, providing flexibility in replacing specific values based on a condition. For example, replacing all positive values in `arr` with the constant 2 can be done using:\n",
    "\n",
    "```python\n",
    "np.where(arr > 0, 2, arr)\n",
    "```\n",
    "\n",
    "This results in an array where only positive values are set to 2, while non-positive values remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])\n",
    "yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])\n",
    "cond = np.array([True, False, True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [(x if c else y)\n",
    "          for x, y, c in zip(xarr, yarr, cond)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where(cond, xarr, yarr)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((4, 4))\n",
    "arr\n",
    "arr > 0\n",
    "np.where(arr > 0, 2, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(arr > 0, 2, arr) # set only positive values to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical and Statistical Methods\n",
    "\n",
    "A collection of mathematical functions designed to calculate statistics for an entire array or along a specific axis is available as methods of the array class in NumPy. These functions, often referred to as aggregations or reductions, include operations like sum, mean, and std (standard deviation), which can be invoked either as instance methods of the array or as top-level NumPy functions. When using the NumPy function, such as numpy.sum, the array to be aggregated needs to be provided as the first argument.\n",
    "\n",
    "Below, I generate a set of normally distributed random data and compute various aggregate statistics:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal((5, 4))\n",
    "```\n",
    "\n",
    "Now, let's explore some of the basic statistical operations:\n",
    "\n",
    "```python\n",
    "arr.mean()   # Output: -0.08719744457434529\n",
    "np.mean(arr)  # Output: -0.08719744457434529\n",
    "arr.sum()    # Output: -1.743948891486906\n",
    "```\n",
    "\n",
    "Functions like mean and sum accept an optional `axis` argument, which computes the statistic over the specified axis, resulting in an array with one less dimension:\n",
    "\n",
    "```python\n",
    "arr.mean(axis=1)  # Output: array([ 0.109 ,  0.3281,  0.165 , -0.6672, -0.3709])\n",
    "arr.sum(axis=0)   # Output: array([-1.6292,  1.0399, -0.3344, -0.8203])\n",
    "```\n",
    "\n",
    "Here, `arr.mean(axis=1)` computes the mean across the columns, while `arr.sum(axis=0)` computes the sum down the rows.\n",
    "\n",
    "Some methods, such as cumsum and cumprod, do not aggregate but produce an array of intermediate results:\n",
    "\n",
    "```python\n",
    "arr = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "arr.cumsum()  # Output: array([ 0,  1,  3,  6, 10, 15, 21, 28])\n",
    "```\n",
    "\n",
    "In multidimensional arrays, accumulation functions like cumsum return an array of the same size but with partial aggregates computed along the indicated axis:\n",
    "\n",
    "```python\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "arr.cumsum(axis=0)\n",
    "# Output:\n",
    "# array([[ 0,  1,  2],\n",
    "#        [ 3,  5,  7],\n",
    "#        [ 9, 12, 15]])\n",
    "arr.cumsum(axis=1)\n",
    "# Output:\n",
    "# array([[ 0,  1,  3],\n",
    "#        [ 3,  7, 12],\n",
    "#        [ 6, 13, 21]])\n",
    "```\n",
    "\n",
    "Table 4.6 provides a comprehensive listing of basic array statistical methods, including sum, mean, std, var, min, max, argmin, argmax, cumsum, and cumprod. These methods prove invaluable for various data analysis tasks and will be further explored in subsequent chapters.\n",
    "\n",
    "\n",
    "**Table 4.6: Basic array statistical methods**\n",
    "\n",
    "| Method    | Description                                                                                           |\n",
    "|-----------|-------------------------------------------------------------------------------------------------------|\n",
    "| `sum`     | Sum of all the elements in the array or along an axis; zero-length arrays have sum 0                   |\n",
    "| `mean`    | Arithmetic mean; invalid (returns NaN) on zero-length arrays                                          |\n",
    "| `std`, `var` | Standard deviation and variance, respectively                                                        |\n",
    "| `min`, `max` | Minimum and maximum                                                                                   |\n",
    "| `argmin`, `argmax` | Indices of minimum and maximum elements, respectively                                            |\n",
    "| `cumsum`  | Cumulative sum of elements starting from 0                                                            |\n",
    "| `cumprod` | Cumulative product of elements starting from 1                                                         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((5, 4))\n",
    "arr\n",
    "arr.mean()\n",
    "np.mean(arr)\n",
    "arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.mean(axis=1)\n",
    "arr.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "arr.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.cumsum(axis=0)\n",
    "arr.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for Boolean Arrays\n",
    "\n",
    "In the methods discussed earlier, Boolean values are automatically converted to numeric values: 1 for `True` and 0 for `False`. This behavior is particularly useful when dealing with Boolean arrays, and the `sum` method, in particular, is commonly employed to count the occurrences of `True` values.\n",
    "\n",
    "For instance:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal(100)\n",
    "positive_count = (arr > 0).sum()  # Counts the number of positive values\n",
    "non_positive_count = (arr <= 0).sum()  # Counts the number of non-positive values\n",
    "```\n",
    "\n",
    "In this example, `(arr > 0).sum()` calculates the number of `True` values, effectively counting the positive elements in the array.\n",
    "\n",
    "Additionally, two other methods, `any` and `all`, are especially useful when working with Boolean arrays. The `any` method checks if at least one value in the array is `True`, while `all` verifies whether all values are `True`. Here's an example:\n",
    "\n",
    "```python\n",
    "bools = np.array([False, False, True, False])\n",
    "any_result = bools.any()  # Returns True if at least one value is True\n",
    "all_result = bools.all()  # Returns False since not all values are True\n",
    "```\n",
    "\n",
    "It's important to note that these methods also operate on non-Boolean arrays, where any non-zero elements are treated as equivalent to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(100)\n",
    "(arr > 0).sum() # Number of positive values\n",
    "(arr <= 0).sum() # Number of non-positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bools = np.array([False, False, True, False])\n",
    "bools.any()\n",
    "bools.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "Similar to Python's built-in list type, NumPy arrays offer an in-place sorting capability through the `sort` method:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal(6)\n",
    "arr.sort()\n",
    "```\n",
    "\n",
    "After applying the `sort` method, the NumPy array `arr` will be rearranged in ascending order. This method is also applicable to multidimensional arrays. When sorting along a specific axis, such as `axis=0` for columns or `axis=1` for rows, each one-dimensional section of values is sorted independently:\n",
    "\n",
    "```python\n",
    "arr = rng.standard_normal((5, 3))\n",
    "arr.sort(axis=0)  # Sorts each column\n",
    "arr.sort(axis=1)  # Sorts across each row\n",
    "```\n",
    "\n",
    "The resulting sorted array, `arr`, reflects the changes made along the specified axis. It's important to note that `sort` modifies the array in place.\n",
    "\n",
    "On the other hand, the top-level method `numpy.sort` returns a sorted copy of the array, leaving the original array unchanged:\n",
    "\n",
    "```python\n",
    "arr2 = np.array([5, -10, 7, 1, 0, -3])\n",
    "sorted_arr2 = np.sort(arr2)\n",
    "```\n",
    "\n",
    "Here, `sorted_arr2` contains the sorted elements of `arr2`, and `arr2` remains unaltered. More advanced sorting techniques and operations can be explored in Appendix A: Advanced NumPy. For more comprehensive data manipulations related to sorting, including scenarios like sorting tables by columns, consider using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(6)\n",
    "arr\n",
    "arr.sort()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal((5, 3))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.sort(axis=0)\n",
    "arr\n",
    "arr.sort(axis=1)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([5, -10, 7, 1, 0, -3])\n",
    "sorted_arr2 = np.sort(arr2)\n",
    "sorted_arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique and Other Set Logic\n",
    "\n",
    "NumPy provides fundamental set operations specifically tailored for one-dimensional ndarrays. One commonly used function is `numpy.unique`, designed to return the sorted unique values present in an array:\n",
    "\n",
    "```python\n",
    "names = np.array([\"Bob\", \"Will\", \"Joe\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n",
    "unique_names = np.unique(names)\n",
    "```\n",
    "\n",
    "In this example, `unique_names` holds the unique values 'Bob', 'Joe', and 'Will'. This function proves advantageous over the pure Python alternative, particularly for larger datasets, as it not only performs faster but also yields a NumPy array rather than a Python list:\n",
    "\n",
    "```python\n",
    "sorted_set_names = sorted(set(names))\n",
    "```\n",
    "\n",
    "Another useful function is `numpy.in1d`, which assesses the membership of values from one array within another, generating a Boolean array:\n",
    "\n",
    "```python\n",
    "values = np.array([6, 0, 0, 3, 2, 5, 6])\n",
    "membership_check = np.in1d(values, [2, 3, 6])\n",
    "```\n",
    "\n",
    "Here, `membership_check` is a Boolean array indicating whether each element of `values` is present in the specified set `[2, 3, 6]`. To explore more array set operations, refer to Table 4.7.\n",
    "\n",
    "Table 4.7: Array Set Operations\n",
    "Method              | Description\n",
    "---------------------|------------------------------------------------------------\n",
    "`unique(x)`         | Compute the sorted, unique elements in array x\n",
    "`intersect1d(x, y)` | Compute the sorted, common elements in arrays x and y\n",
    "`union1d(x, y)`     | Compute the sorted union of elements from arrays x and y\n",
    "`in1d(x, y)`        | Compute a Boolean array indicating membership of x's elements in y\n",
    "`setdiff1d(x, y)`   | Set difference - elements in x that are not in y\n",
    "`setxor1d(x, y)`    | Set symmetric differences - elements in either array, but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array([\"Bob\", \"Will\", \"Joe\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n",
    "np.unique(names)\n",
    "ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])\n",
    "np.unique(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([6, 0, 0, 3, 2, 5, 6])\n",
    "np.in1d(values, [2, 3, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 File Input and Output with Arrays\n",
    "\n",
    "NumPy offers functionality for saving and loading data to and from disk, supporting various text and binary formats. This discussion focuses on NumPy's built-in binary format, as most users typically prefer tools like pandas for handling text or tabular data (refer to Chapter 6: Data Loading, Storage, and File Formats for more comprehensive details).\n",
    "\n",
    "The primary functions for efficient array data storage and retrieval on disk are numpy.save and numpy.load. By default, arrays are saved in an uncompressed raw binary format with the file extension .npy. For instance:\n",
    "\n",
    "```python\n",
    "arr = np.arange(10)\n",
    "np.save(\"some_array\", arr)\n",
    "```\n",
    "\n",
    "If the file path lacks the .npy extension, it will be automatically appended. The saved array can then be loaded using numpy.load:\n",
    "\n",
    "```python\n",
    "loaded_arr = np.load(\"some_array.npy\")\n",
    "print(loaded_arr)  # Output: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "```\n",
    "\n",
    "For saving multiple arrays in an uncompressed archive, numpy.savez is used, passing the arrays as keyword arguments:\n",
    "\n",
    "```python\n",
    "np.savez(\"array_archive.npz\", a=arr, b=arr)\n",
    "```\n",
    "\n",
    "When loading an .npz file, a dictionary-like object is obtained, allowing lazy loading of individual arrays:\n",
    "\n",
    "```python\n",
    "archive = np.load(\"array_archive.npz\")\n",
    "print(archive[\"b\"])  # Output: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "```\n",
    "\n",
    "For data that compresses well, numpy.savez_compressed can be employed:\n",
    "\n",
    "```python\n",
    "np.savez_compressed(\"arrays_compressed.npz\", a=arr, b=arr)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "np.save(\"some_array\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"some_array.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"array_archive.npz\", a=arr, b=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load(\"array_archive.npz\")\n",
    "arch[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"arrays_compressed.npz\", a=arr, b=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm some_array.npy\n",
    "!rm array_archive.npz\n",
    "!rm arrays_compressed.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.6 Linear Algebra\n",
    "\n",
    "Linear algebra operations play a crucial role in many array libraries, involving tasks such as matrix multiplication, decompositions, determinants, and other operations related to square matrices. In the context of NumPy, multiplying two two-dimensional arrays using * results in an element-wise product. For true matrix multiplications, the dot function or the @ infix operator is employed. The dot function exists both as an array method and a function in the numpy namespace, facilitating matrix multiplication:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "y = np.array([[6., 23.], [-1, 7], [8, 9]])\n",
    "\n",
    "result_dot = x.dot(y)\n",
    "result_np_dot = np.dot(x, y)\n",
    "result_at_operator = x @ y\n",
    "\n",
    "print(result_dot)\n",
    "print(result_np_dot)\n",
    "print(result_at_operator)\n",
    "```\n",
    "\n",
    "The numpy.linalg module provides a standard set of matrix decompositions, as well as operations like inverse and determinant:\n",
    "\n",
    "```python\n",
    "from numpy.linalg import inv, qr\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "X = rng.standard_normal((5, 5))\n",
    "mat = X.T @ X\n",
    "\n",
    "inverse_mat = inv(mat)\n",
    "product_mat_inverse = mat @ inv(mat)\n",
    "\n",
    "print(inverse_mat)\n",
    "print(product_mat_inverse)\n",
    "```\n",
    "\n",
    "Furthermore, numpy.linalg includes various commonly used linear algebra functions, as outlined in Table 4.8:\n",
    "\n",
    "Table 4.8: Commonly used numpy.linalg functions\n",
    "\n",
    "Certainly! Here's the table:\n",
    "\n",
    "| Function | Description                                                       |\n",
    "|----------|-------------------------------------------------------------------|\n",
    "| diag     | Return the diagonal (or off-diagonal) elements of a square matrix as a 1D array, or convert a 1D array into a square matrix with zeros on the off-diagonal. |\n",
    "| dot      | Matrix multiplication.                                            |\n",
    "| trace    | Compute the sum of the diagonal elements.                         |\n",
    "| det      | Compute the matrix determinant.                                   |\n",
    "| eig      | Compute the eigenvalues and eigenvectors of a square matrix.      |\n",
    "| inv      | Compute the inverse of a square matrix.                           |\n",
    "| pinv     | Compute the Moore-Penrose pseudoinverse of a matrix.              |\n",
    "| qr       | Compute the QR decomposition.                                     |\n",
    "| svd      | Compute the singular value decomposition (SVD).                  |\n",
    "| solve    | Solve the linear system Ax = b for x, where A is a square matrix. |\n",
    "| lstsq    | Compute the least-squares solution to Ax = b.                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "y = np.array([[6., 23.], [-1, 7], [8, 9]])\n",
    "x\n",
    "y\n",
    "x.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x @ np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv, qr\n",
    "X = rng.standard_normal((5, 5))\n",
    "mat = X.T @ X\n",
    "inv(mat)\n",
    "mat @ inv(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Example: Random Walks\n",
    "\n",
    "The simulation of random walks serves as an insightful application to showcase the utilization of array operations. Initially, let's examine a basic random walk starting at 0, with steps of 1 and -1 occurring with equal probability.\n",
    "\n",
    "To implement a single random walk with 1,000 steps in pure Python, one can use the built-in random module:\n",
    "\n",
    "```python\n",
    "import random\n",
    "position = 0\n",
    "walk = [position]\n",
    "nsteps = 1000\n",
    "for _ in range(nsteps):\n",
    "    step = 1 if random.randint(0, 1) else -1\n",
    "    position += step\n",
    "    walk.append(position)\n",
    "```\n",
    "\n",
    "The resulting `walk` list represents the cumulative sum of the random steps. Alternatively, utilizing the `numpy.random` module enables a more efficient approach by drawing 1,000 coin flips at once, setting these to 1 and -1, and computing the cumulative sum:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "nsteps = 1000\n",
    "rng = np.random.default_rng(seed=12345)  # fresh random generator\n",
    "draws = rng.integers(0, 2, size=nsteps)\n",
    "steps = np.where(draws == 0, 1, -1)\n",
    "walk = steps.cumsum()\n",
    "```\n",
    "\n",
    "This numpy-based implementation facilitates extracting statistics such as the minimum and maximum values along the walk’s trajectory:\n",
    "\n",
    "```python\n",
    "walk.min()  # Output: -8\n",
    "walk.max()  # Output: 50\n",
    "```\n",
    "\n",
    "Additionally, we can compute a more complex statistic, the first crossing time, which indicates the step at which the random walk reaches a particular value. For example, determining how long it took the random walk to get at least 10 steps away from the origin (0) in either direction. This can be achieved using the `argmax` function, which returns the first index of the maximum value in a Boolean array (where `True` is considered the maximum value):\n",
    "\n",
    "```python\n",
    "(np.abs(walk) >= 10).argmax()  # Output: 155\n",
    "```\n",
    "\n",
    "It's worth noting that using `argmax` might not always be the most efficient choice, as it necessitates a full scan of the array. In this specific case, efficiency could be improved since, once a `True` value is observed, it is known to be the maximum value in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "position = 0\n",
    "walk = [position]\n",
    "nsteps = 1000\n",
    "for _ in range(nsteps):\n",
    "    step = 1 if random.randint(0, 1) else -1\n",
    "    position += step\n",
    "    walk.append(position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 if random.randint(0, 1) else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(walk[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1000\n",
    "rng = np.random.default_rng(seed=12345)  # fresh random generator\n",
    "draws = rng.integers(0, 2, size=nsteps)\n",
    "steps = np.where(draws == 0, 1, -1)\n",
    "walk = steps.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk.min()\n",
    "walk.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(walk) >= 10).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Many Random Walks at Once\n",
    "\n",
    "If the objective is to simulate a large number of random walks, for example, five thousand of them, slight modifications to the previous code can generate all the random walks efficiently. When passed a 2-tuple, numpy.random functions generate a two-dimensional array of draws. By computing the cumulative sum for each row, all five thousand random walks can be calculated in a single operation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "nwalks = 5000\n",
    "nsteps = 1000\n",
    "\n",
    "draws = rng.integers(0, 2, size=(nwalks, nsteps))  # 0 or 1\n",
    "steps = np.where(draws > 0, 1, -1)\n",
    "walks = steps.cumsum(axis=1)\n",
    "```\n",
    "\n",
    "This results in a two-dimensional array (`walks`) representing all the random walks, where each row corresponds to a different walk.\n",
    "\n",
    "Now, various statistics can be computed across all walks, such as the maximum and minimum values:\n",
    "\n",
    "```python\n",
    "walks.max()  # Output: 114\n",
    "walks.min()  # Output: -120\n",
    "```\n",
    "\n",
    "To find the minimum crossing time to reach a value of 30 or -30, a Boolean array can be generated to identify walks that reach or exceed 30 in absolute value. The `any` method is employed along axis=1 to check for any True values in each row:\n",
    "\n",
    "```python\n",
    "hits30 = (np.abs(walks) >= 30).any(axis=1)\n",
    "hits30.sum()  # Number of walks that hit 30 or -30 (Output: 3395)\n",
    "```\n",
    "\n",
    "Using this Boolean array, rows of walks that actually cross the absolute 30 level can be selected. The `argmax` function is then applied along axis=1 to determine the crossing times:\n",
    "\n",
    "```python\n",
    "crossing_times = (np.abs(walks[hits30]) >= 30).argmax(axis=1)\n",
    "crossing_times  # Array of crossing times\n",
    "```\n",
    "\n",
    "Finally, the average minimum crossing time can be computed:\n",
    "\n",
    "```python\n",
    "crossing_times.mean()  # Output: 500.5699558173785\n",
    "```\n",
    "\n",
    "It's worth noting that while this vectorized approach is efficient, it requires creating an array with nwalks * nsteps elements, potentially consuming a significant amount of memory for large simulations. If memory constraints are a concern, alternative approaches should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalks = 5000\n",
    "nsteps = 1000\n",
    "draws = rng.integers(0, 2, size=(nwalks, nsteps)) # 0 or 1\n",
    "steps = np.where(draws > 0, 1, -1)\n",
    "walks = steps.cumsum(axis=1)\n",
    "walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks.max()\n",
    "walks.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits30 = (np.abs(walks) >= 30).any(axis=1)\n",
    "hits30\n",
    "hits30.sum() # Number that hit 30 or -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossing_times = (np.abs(walks[hits30]) >= 30).argmax(axis=1)\n",
    "crossing_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossing_times.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = 0.25 * rng.standard_normal((nwalks, nsteps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
